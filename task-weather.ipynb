{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e006b9c4-af66-439e-963d-b5a387e1d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "rain_float_map = {\n",
    "    \"rain\": 1.0,\n",
    "    b'rain': 1.0,\n",
    "    \"no rain\": 0.0,\n",
    "    b'no rain': 0.0\n",
    "}\n",
    "\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, file_path=\"weather_forecast_data.csv\", transform=None, target_transform=None):\n",
    "        self.records = np.genfromtxt(\n",
    "            file_path, \n",
    "            dtype=\"f8\",\n",
    "            delimiter=\",\", \n",
    "            skip_header=1, \n",
    "            converters={5: lambda s: rain_float_map.get(s) }\n",
    "        ).astype(np.float32)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.records[idx]\n",
    "        x = torch.from_numpy(record[:-1])\n",
    "        y = torch.from_numpy(np.atleast_1d(record[-1]))\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6904ed-1818-42fa-a81c-d55db609e55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LargerModel(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "#------------------------------------------------\n",
    "\n",
    "class ModelWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  \n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "class ModelWithLeakyReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "#--------------------------------------------------\n",
    "\n",
    "class LargerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "\n",
    "model = LargerModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43be92cf-5912-4856-bd6f-c46e7b8bf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            binary_pred = torch.where(pred.sigmoid() > 0.8, 1.0, 0.0)\n",
    "            correct += (binary_pred == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d092600f-dd2e-4af5-aa2a-a51d407b2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_dataset = WeatherDataset()\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [0.8, 0.2])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718d4d22-4276-431a-b35b-66535e45c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c2d157-6fd2-47ed-b782-6bcdc110c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model: NeuralNetwork, Optimizer: SGD, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.647855  [   64/ 2000]\n",
      "loss: 0.636855  [  704/ 2000]\n",
      "loss: 0.624421  [ 1344/ 2000]\n",
      "loss: 0.603584  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.592807  [   64/ 2000]\n",
      "loss: 0.595060  [  704/ 2000]\n",
      "loss: 0.577831  [ 1344/ 2000]\n",
      "loss: 0.578257  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.552969  [   64/ 2000]\n",
      "loss: 0.534558  [  704/ 2000]\n",
      "loss: 0.543555  [ 1344/ 2000]\n",
      "loss: 0.541714  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.524779  [   64/ 2000]\n",
      "loss: 0.539497  [  704/ 2000]\n",
      "loss: 0.558103  [ 1344/ 2000]\n",
      "loss: 0.507260  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.561339  [   64/ 2000]\n",
      "loss: 0.518053  [  704/ 2000]\n",
      "loss: 0.492128  [ 1344/ 2000]\n",
      "loss: 0.517036  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.483845  [   64/ 2000]\n",
      "loss: 0.477512  [  704/ 2000]\n",
      "loss: 0.449122  [ 1344/ 2000]\n",
      "loss: 0.537725  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.440994  [   64/ 2000]\n",
      "loss: 0.496922  [  704/ 2000]\n",
      "loss: 0.454683  [ 1344/ 2000]\n",
      "loss: 0.516013  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.409493  [   64/ 2000]\n",
      "loss: 0.444767  [  704/ 2000]\n",
      "loss: 0.454742  [ 1344/ 2000]\n",
      "loss: 0.436763  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.450198  [   64/ 2000]\n",
      "loss: 0.446990  [  704/ 2000]\n",
      "loss: 0.473778  [ 1344/ 2000]\n",
      "loss: 0.471190  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.501674  [   64/ 2000]\n",
      "loss: 0.468306  [  704/ 2000]\n",
      "loss: 0.498472  [ 1344/ 2000]\n",
      "loss: 0.464312  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.4315\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: SGD, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.920414  [   64/ 2000]\n",
      "loss: 0.480577  [  704/ 2000]\n",
      "loss: 0.517055  [ 1344/ 2000]\n",
      "loss: 0.347021  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.606188  [   64/ 2000]\n",
      "loss: 0.351710  [  704/ 2000]\n",
      "loss: 0.330279  [ 1344/ 2000]\n",
      "loss: 0.282363  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.419560  [   64/ 2000]\n",
      "loss: 0.299343  [  704/ 2000]\n",
      "loss: 0.335358  [ 1344/ 2000]\n",
      "loss: 0.546996  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.376102  [   64/ 2000]\n",
      "loss: 0.272048  [  704/ 2000]\n",
      "loss: 0.360301  [ 1344/ 2000]\n",
      "loss: 0.355489  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.332520  [   64/ 2000]\n",
      "loss: 0.321080  [  704/ 2000]\n",
      "loss: 0.325913  [ 1344/ 2000]\n",
      "loss: 0.382808  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.321449  [   64/ 2000]\n",
      "loss: 0.320668  [  704/ 2000]\n",
      "loss: 0.203658  [ 1344/ 2000]\n",
      "loss: 0.333182  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.340889  [   64/ 2000]\n",
      "loss: 0.424341  [  704/ 2000]\n",
      "loss: 0.349675  [ 1344/ 2000]\n",
      "loss: 0.318864  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.399946  [   64/ 2000]\n",
      "loss: 0.430736  [  704/ 2000]\n",
      "loss: 0.365363  [ 1344/ 2000]\n",
      "loss: 0.496737  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.337687  [   64/ 2000]\n",
      "loss: 0.297263  [  704/ 2000]\n",
      "loss: 0.300346  [ 1344/ 2000]\n",
      "loss: 0.216156  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.344858  [   64/ 2000]\n",
      "loss: 0.279978  [  704/ 2000]\n",
      "loss: 0.300868  [ 1344/ 2000]\n",
      "loss: 0.410290  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3373\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: SGD, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 29.500511  [   64/ 2000]\n",
      "loss: 1.276605  [  704/ 2000]\n",
      "loss: 0.689999  [ 1344/ 2000]\n",
      "loss: 0.567725  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.605301  [   64/ 2000]\n",
      "loss: 0.639801  [  704/ 2000]\n",
      "loss: 0.886771  [ 1344/ 2000]\n",
      "loss: 0.574210  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.561634  [   64/ 2000]\n",
      "loss: 0.511874  [  704/ 2000]\n",
      "loss: 0.589025  [ 1344/ 2000]\n",
      "loss: 1.041719  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.589760  [   64/ 2000]\n",
      "loss: 0.864615  [  704/ 2000]\n",
      "loss: 0.649304  [ 1344/ 2000]\n",
      "loss: 0.722868  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.954871  [   64/ 2000]\n",
      "loss: 0.619470  [  704/ 2000]\n",
      "loss: 0.580218  [ 1344/ 2000]\n",
      "loss: 0.629320  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.499360  [   64/ 2000]\n",
      "loss: 0.600079  [  704/ 2000]\n",
      "loss: 0.833564  [ 1344/ 2000]\n",
      "loss: 0.349228  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.576986  [   64/ 2000]\n",
      "loss: 0.477691  [  704/ 2000]\n",
      "loss: 0.377757  [ 1344/ 2000]\n",
      "loss: 0.827759  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.545233  [   64/ 2000]\n",
      "loss: 0.308690  [  704/ 2000]\n",
      "loss: 0.875855  [ 1344/ 2000]\n",
      "loss: 0.856270  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.744666  [   64/ 2000]\n",
      "loss: 0.454086  [  704/ 2000]\n",
      "loss: 0.387063  [ 1344/ 2000]\n",
      "loss: 0.646123  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.690077  [   64/ 2000]\n",
      "loss: 0.566580  [  704/ 2000]\n",
      "loss: 0.635721  [ 1344/ 2000]\n",
      "loss: 0.413790  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8660, Avg Loss: 0.5879\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: Adam, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 53.370701  [   64/ 2000]\n",
      "loss: 0.785578  [  704/ 2000]\n",
      "loss: 0.574298  [ 1344/ 2000]\n",
      "loss: 0.514915  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.549759  [   64/ 2000]\n",
      "loss: 0.367699  [  704/ 2000]\n",
      "loss: 0.389939  [ 1344/ 2000]\n",
      "loss: 0.245150  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.414959  [   64/ 2000]\n",
      "loss: 0.422082  [  704/ 2000]\n",
      "loss: 0.387898  [ 1344/ 2000]\n",
      "loss: 0.387814  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.418112  [   64/ 2000]\n",
      "loss: 0.358227  [  704/ 2000]\n",
      "loss: 0.276938  [ 1344/ 2000]\n",
      "loss: 0.348138  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.444223  [   64/ 2000]\n",
      "loss: 0.353782  [  704/ 2000]\n",
      "loss: 0.336974  [ 1344/ 2000]\n",
      "loss: 0.417933  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.292268  [   64/ 2000]\n",
      "loss: 0.446282  [  704/ 2000]\n",
      "loss: 0.364748  [ 1344/ 2000]\n",
      "loss: 0.350046  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.321167  [   64/ 2000]\n",
      "loss: 0.416153  [  704/ 2000]\n",
      "loss: 0.283219  [ 1344/ 2000]\n",
      "loss: 0.340364  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.383047  [   64/ 2000]\n",
      "loss: 0.358498  [  704/ 2000]\n",
      "loss: 0.491826  [ 1344/ 2000]\n",
      "loss: 0.413129  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.284178  [   64/ 2000]\n",
      "loss: 0.407216  [  704/ 2000]\n",
      "loss: 0.460724  [ 1344/ 2000]\n",
      "loss: 0.345229  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.354070  [   64/ 2000]\n",
      "loss: 0.351034  [  704/ 2000]\n",
      "loss: 0.432311  [ 1344/ 2000]\n",
      "loss: 0.348492  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3871\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: Adam, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 15.623721  [   64/ 2000]\n",
      "loss: 0.657216  [  704/ 2000]\n",
      "loss: 1.741366  [ 1344/ 2000]\n",
      "loss: 1.311273  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.516907  [   64/ 2000]\n",
      "loss: 0.827868  [  704/ 2000]\n",
      "loss: 0.555003  [ 1344/ 2000]\n",
      "loss: 0.479325  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.702226  [   64/ 2000]\n",
      "loss: 0.352062  [  704/ 2000]\n",
      "loss: 0.331967  [ 1344/ 2000]\n",
      "loss: 0.341897  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.323051  [   64/ 2000]\n",
      "loss: 0.454872  [  704/ 2000]\n",
      "loss: 0.423393  [ 1344/ 2000]\n",
      "loss: 0.347135  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.439628  [   64/ 2000]\n",
      "loss: 0.468714  [  704/ 2000]\n",
      "loss: 0.439767  [ 1344/ 2000]\n",
      "loss: 0.388376  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.467104  [   64/ 2000]\n",
      "loss: 0.484968  [  704/ 2000]\n",
      "loss: 0.392482  [ 1344/ 2000]\n",
      "loss: 0.302168  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.622287  [   64/ 2000]\n",
      "loss: 0.369037  [  704/ 2000]\n",
      "loss: 0.360775  [ 1344/ 2000]\n",
      "loss: 0.409997  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.610936  [   64/ 2000]\n",
      "loss: 0.374302  [  704/ 2000]\n",
      "loss: 0.406054  [ 1344/ 2000]\n",
      "loss: 0.313211  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.455626  [   64/ 2000]\n",
      "loss: 0.259130  [  704/ 2000]\n",
      "loss: 0.339255  [ 1344/ 2000]\n",
      "loss: 0.409071  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.240752  [   64/ 2000]\n",
      "loss: 0.351764  [  704/ 2000]\n",
      "loss: 0.280716  [ 1344/ 2000]\n",
      "loss: 0.475297  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3446\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: Adam, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.278859  [   64/ 2000]\n",
      "loss: 0.855299  [  704/ 2000]\n",
      "loss: 1.119475  [ 1344/ 2000]\n",
      "loss: 0.763560  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.659074  [   64/ 2000]\n",
      "loss: 0.320202  [  704/ 2000]\n",
      "loss: 0.437382  [ 1344/ 2000]\n",
      "loss: 0.272723  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.254873  [   64/ 2000]\n",
      "loss: 0.376954  [  704/ 2000]\n",
      "loss: 0.354096  [ 1344/ 2000]\n",
      "loss: 0.296418  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.356547  [   64/ 2000]\n",
      "loss: 0.343291  [  704/ 2000]\n",
      "loss: 0.356389  [ 1344/ 2000]\n",
      "loss: 0.405530  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.425530  [   64/ 2000]\n",
      "loss: 0.266288  [  704/ 2000]\n",
      "loss: 0.341275  [ 1344/ 2000]\n",
      "loss: 0.496660  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.426413  [   64/ 2000]\n",
      "loss: 0.472849  [  704/ 2000]\n",
      "loss: 0.282248  [ 1344/ 2000]\n",
      "loss: 0.339841  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.459325  [   64/ 2000]\n",
      "loss: 0.411021  [  704/ 2000]\n",
      "loss: 0.283088  [ 1344/ 2000]\n",
      "loss: 0.301871  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.543766  [   64/ 2000]\n",
      "loss: 0.373981  [  704/ 2000]\n",
      "loss: 0.373142  [ 1344/ 2000]\n",
      "loss: 0.309233  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.346084  [   64/ 2000]\n",
      "loss: 0.314732  [  704/ 2000]\n",
      "loss: 0.296205  [ 1344/ 2000]\n",
      "loss: 0.407024  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.291459  [   64/ 2000]\n",
      "loss: 0.494366  [  704/ 2000]\n",
      "loss: 0.484733  [ 1344/ 2000]\n",
      "loss: 0.497995  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3535\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: RMSprop, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 34.816364  [   64/ 2000]\n",
      "loss: 1.405044  [  704/ 2000]\n",
      "loss: 0.390821  [ 1344/ 2000]\n",
      "loss: 0.320574  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.295289  [   64/ 2000]\n",
      "loss: 0.317749  [  704/ 2000]\n",
      "loss: 0.151253  [ 1344/ 2000]\n",
      "loss: 0.204727  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.236299  [   64/ 2000]\n",
      "loss: 0.287982  [  704/ 2000]\n",
      "loss: 0.205712  [ 1344/ 2000]\n",
      "loss: 0.223115  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.444995  [   64/ 2000]\n",
      "loss: 0.283514  [  704/ 2000]\n",
      "loss: 0.179986  [ 1344/ 2000]\n",
      "loss: 0.266594  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.179637  [   64/ 2000]\n",
      "loss: 0.233482  [  704/ 2000]\n",
      "loss: 0.160294  [ 1344/ 2000]\n",
      "loss: 0.262429  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.330118  [   64/ 2000]\n",
      "loss: 0.277104  [  704/ 2000]\n",
      "loss: 0.247317  [ 1344/ 2000]\n",
      "loss: 0.104384  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.201232  [   64/ 2000]\n",
      "loss: 0.170295  [  704/ 2000]\n",
      "loss: 0.253025  [ 1344/ 2000]\n",
      "loss: 0.116852  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.321325  [   64/ 2000]\n",
      "loss: 0.181722  [  704/ 2000]\n",
      "loss: 0.209629  [ 1344/ 2000]\n",
      "loss: 0.174527  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.238929  [   64/ 2000]\n",
      "loss: 0.147020  [  704/ 2000]\n",
      "loss: 0.188493  [ 1344/ 2000]\n",
      "loss: 0.137043  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.238204  [   64/ 2000]\n",
      "loss: 0.200032  [  704/ 2000]\n",
      "loss: 0.172282  [ 1344/ 2000]\n",
      "loss: 0.107708  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8580, Avg Loss: 0.2826\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: RMSprop, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 17.168112  [   64/ 2000]\n",
      "loss: 0.557502  [  704/ 2000]\n",
      "loss: 0.243238  [ 1344/ 2000]\n",
      "loss: 0.259569  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.157467  [   64/ 2000]\n",
      "loss: 0.336293  [  704/ 2000]\n",
      "loss: 0.182798  [ 1344/ 2000]\n",
      "loss: 0.236006  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.961845  [   64/ 2000]\n",
      "loss: 0.204729  [  704/ 2000]\n",
      "loss: 0.237134  [ 1344/ 2000]\n",
      "loss: 0.296352  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.277826  [   64/ 2000]\n",
      "loss: 0.436322  [  704/ 2000]\n",
      "loss: 0.410105  [ 1344/ 2000]\n",
      "loss: 0.230064  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.239570  [   64/ 2000]\n",
      "loss: 0.394931  [  704/ 2000]\n",
      "loss: 0.133930  [ 1344/ 2000]\n",
      "loss: 0.223027  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.082727  [   64/ 2000]\n",
      "loss: 0.317819  [  704/ 2000]\n",
      "loss: 0.250965  [ 1344/ 2000]\n",
      "loss: 0.233153  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.308631  [   64/ 2000]\n",
      "loss: 0.240197  [  704/ 2000]\n",
      "loss: 0.253056  [ 1344/ 2000]\n",
      "loss: 0.360395  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.455032  [   64/ 2000]\n",
      "loss: 0.237801  [  704/ 2000]\n",
      "loss: 0.294163  [ 1344/ 2000]\n",
      "loss: 0.266598  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.180249  [   64/ 2000]\n",
      "loss: 0.343408  [  704/ 2000]\n",
      "loss: 0.303797  [ 1344/ 2000]\n",
      "loss: 0.395240  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.198758  [   64/ 2000]\n",
      "loss: 0.186538  [  704/ 2000]\n",
      "loss: 0.180444  [ 1344/ 2000]\n",
      "loss: 0.447659  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8740, Avg Loss: 0.3514\n",
      "\n",
      "Testing model: NeuralNetwork, Optimizer: RMSprop, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.655553  [   64/ 2000]\n",
      "loss: 0.424899  [  704/ 2000]\n",
      "loss: 0.424481  [ 1344/ 2000]\n",
      "loss: 0.352273  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.376686  [   64/ 2000]\n",
      "loss: 0.419533  [  704/ 2000]\n",
      "loss: 0.495852  [ 1344/ 2000]\n",
      "loss: 0.512001  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.626548  [   64/ 2000]\n",
      "loss: 0.513625  [  704/ 2000]\n",
      "loss: 0.405613  [ 1344/ 2000]\n",
      "loss: 0.489669  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.312865  [   64/ 2000]\n",
      "loss: 0.701800  [  704/ 2000]\n",
      "loss: 0.427274  [ 1344/ 2000]\n",
      "loss: 0.529781  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.553772  [   64/ 2000]\n",
      "loss: 0.346407  [  704/ 2000]\n",
      "loss: 0.378927  [ 1344/ 2000]\n",
      "loss: 0.555461  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.325267  [   64/ 2000]\n",
      "loss: 0.413259  [  704/ 2000]\n",
      "loss: 0.385752  [ 1344/ 2000]\n",
      "loss: 0.504499  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.466574  [   64/ 2000]\n",
      "loss: 0.693699  [  704/ 2000]\n",
      "loss: 0.493817  [ 1344/ 2000]\n",
      "loss: 0.446702  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.573384  [   64/ 2000]\n",
      "loss: 0.322810  [  704/ 2000]\n",
      "loss: 0.437539  [ 1344/ 2000]\n",
      "loss: 0.271622  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.398668  [   64/ 2000]\n",
      "loss: 0.345954  [  704/ 2000]\n",
      "loss: 0.448080  [ 1344/ 2000]\n",
      "loss: 0.343174  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.454492  [   64/ 2000]\n",
      "loss: 0.413999  [  704/ 2000]\n",
      "loss: 0.380739  [ 1344/ 2000]\n",
      "loss: 0.704110  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3997\n",
      "\n",
      "Testing model: LargerModel, Optimizer: SGD, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 16.773008  [   64/ 2000]\n",
      "loss: 0.763275  [  704/ 2000]\n",
      "loss: 0.705677  [ 1344/ 2000]\n",
      "loss: 0.684233  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.672927  [   64/ 2000]\n",
      "loss: 0.654500  [  704/ 2000]\n",
      "loss: 0.619709  [ 1344/ 2000]\n",
      "loss: 0.626144  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.615673  [   64/ 2000]\n",
      "loss: 0.590216  [  704/ 2000]\n",
      "loss: 0.628250  [ 1344/ 2000]\n",
      "loss: 0.568836  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.578354  [   64/ 2000]\n",
      "loss: 0.547882  [  704/ 2000]\n",
      "loss: 0.529302  [ 1344/ 2000]\n",
      "loss: 0.525886  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.539938  [   64/ 2000]\n",
      "loss: 0.513677  [  704/ 2000]\n",
      "loss: 0.494524  [ 1344/ 2000]\n",
      "loss: 0.504591  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.523420  [   64/ 2000]\n",
      "loss: 0.463856  [  704/ 2000]\n",
      "loss: 0.488241  [ 1344/ 2000]\n",
      "loss: 0.492270  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.515050  [   64/ 2000]\n",
      "loss: 0.448364  [  704/ 2000]\n",
      "loss: 0.479546  [ 1344/ 2000]\n",
      "loss: 0.474227  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.473054  [   64/ 2000]\n",
      "loss: 0.454116  [  704/ 2000]\n",
      "loss: 0.477878  [ 1344/ 2000]\n",
      "loss: 0.488970  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.533837  [   64/ 2000]\n",
      "loss: 0.454379  [  704/ 2000]\n",
      "loss: 0.434720  [ 1344/ 2000]\n",
      "loss: 0.414122  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.346884  [   64/ 2000]\n",
      "loss: 0.477207  [  704/ 2000]\n",
      "loss: 0.388128  [ 1344/ 2000]\n",
      "loss: 0.383777  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.4235\n",
      "\n",
      "Testing model: LargerModel, Optimizer: SGD, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.095048  [   64/ 2000]\n",
      "loss: 0.345382  [  704/ 2000]\n",
      "loss: 0.353490  [ 1344/ 2000]\n",
      "loss: 0.283894  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.434033  [   64/ 2000]\n",
      "loss: 0.382759  [  704/ 2000]\n",
      "loss: 0.331404  [ 1344/ 2000]\n",
      "loss: 0.395809  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.466266  [   64/ 2000]\n",
      "loss: 0.328653  [  704/ 2000]\n",
      "loss: 0.301842  [ 1344/ 2000]\n",
      "loss: 0.405828  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.366864  [   64/ 2000]\n",
      "loss: 0.365287  [  704/ 2000]\n",
      "loss: 0.545350  [ 1344/ 2000]\n",
      "loss: 0.307335  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.407341  [   64/ 2000]\n",
      "loss: 0.359102  [  704/ 2000]\n",
      "loss: 0.411221  [ 1344/ 2000]\n",
      "loss: 0.297517  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.417200  [   64/ 2000]\n",
      "loss: 0.311126  [  704/ 2000]\n",
      "loss: 0.414551  [ 1344/ 2000]\n",
      "loss: 0.278367  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.421937  [   64/ 2000]\n",
      "loss: 0.464749  [  704/ 2000]\n",
      "loss: 0.323560  [ 1344/ 2000]\n",
      "loss: 0.259454  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.480555  [   64/ 2000]\n",
      "loss: 0.321861  [  704/ 2000]\n",
      "loss: 0.323123  [ 1344/ 2000]\n",
      "loss: 0.355406  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.433488  [   64/ 2000]\n",
      "loss: 0.361293  [  704/ 2000]\n",
      "loss: 0.365431  [ 1344/ 2000]\n",
      "loss: 0.231247  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.297211  [   64/ 2000]\n",
      "loss: 0.451980  [  704/ 2000]\n",
      "loss: 0.406619  [ 1344/ 2000]\n",
      "loss: 0.234103  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8700, Avg Loss: 0.5734\n",
      "\n",
      "Testing model: LargerModel, Optimizer: SGD, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.071978  [   64/ 2000]\n",
      "loss: 0.304390  [  704/ 2000]\n",
      "loss: 0.490858  [ 1344/ 2000]\n",
      "loss: 0.393027  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.419137  [   64/ 2000]\n",
      "loss: 0.306634  [  704/ 2000]\n",
      "loss: 0.302804  [ 1344/ 2000]\n",
      "loss: 0.395827  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.360723  [   64/ 2000]\n",
      "loss: 0.391643  [  704/ 2000]\n",
      "loss: 0.332732  [ 1344/ 2000]\n",
      "loss: 0.389551  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.464688  [   64/ 2000]\n",
      "loss: 0.259776  [  704/ 2000]\n",
      "loss: 0.387108  [ 1344/ 2000]\n",
      "loss: 0.278997  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.371408  [   64/ 2000]\n",
      "loss: 0.330108  [  704/ 2000]\n",
      "loss: 0.432272  [ 1344/ 2000]\n",
      "loss: 0.459451  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.433939  [   64/ 2000]\n",
      "loss: 0.428182  [  704/ 2000]\n",
      "loss: 0.300041  [ 1344/ 2000]\n",
      "loss: 0.416435  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.378021  [   64/ 2000]\n",
      "loss: 0.329441  [  704/ 2000]\n",
      "loss: 0.406831  [ 1344/ 2000]\n",
      "loss: 0.322417  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.371891  [   64/ 2000]\n",
      "loss: 0.314289  [  704/ 2000]\n",
      "loss: 0.319523  [ 1344/ 2000]\n",
      "loss: 0.440871  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.452957  [   64/ 2000]\n",
      "loss: 0.383442  [  704/ 2000]\n",
      "loss: 0.358096  [ 1344/ 2000]\n",
      "loss: 0.406188  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.289626  [   64/ 2000]\n",
      "loss: 0.263465  [  704/ 2000]\n",
      "loss: 0.234683  [ 1344/ 2000]\n",
      "loss: 0.412625  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3489\n",
      "\n",
      "Testing model: LargerModel, Optimizer: Adam, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.891318  [   64/ 2000]\n",
      "loss: 0.340612  [  704/ 2000]\n",
      "loss: 0.824524  [ 1344/ 2000]\n",
      "loss: 0.440498  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.372067  [   64/ 2000]\n",
      "loss: 0.257817  [  704/ 2000]\n",
      "loss: 0.360959  [ 1344/ 2000]\n",
      "loss: 0.331877  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.424594  [   64/ 2000]\n",
      "loss: 0.279785  [  704/ 2000]\n",
      "loss: 0.299130  [ 1344/ 2000]\n",
      "loss: 0.215943  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.288504  [   64/ 2000]\n",
      "loss: 0.229379  [  704/ 2000]\n",
      "loss: 0.451793  [ 1344/ 2000]\n",
      "loss: 0.407407  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.196226  [   64/ 2000]\n",
      "loss: 0.311060  [  704/ 2000]\n",
      "loss: 0.226035  [ 1344/ 2000]\n",
      "loss: 0.287291  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.181911  [   64/ 2000]\n",
      "loss: 0.136883  [  704/ 2000]\n",
      "loss: 0.280717  [ 1344/ 2000]\n",
      "loss: 0.307988  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.332680  [   64/ 2000]\n",
      "loss: 0.267981  [  704/ 2000]\n",
      "loss: 0.366588  [ 1344/ 2000]\n",
      "loss: 0.184304  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.241677  [   64/ 2000]\n",
      "loss: 0.164046  [  704/ 2000]\n",
      "loss: 0.229782  [ 1344/ 2000]\n",
      "loss: 0.171749  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.159209  [   64/ 2000]\n",
      "loss: 0.183221  [  704/ 2000]\n",
      "loss: 0.218607  [ 1344/ 2000]\n",
      "loss: 0.129834  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.289589  [   64/ 2000]\n",
      "loss: 0.265968  [  704/ 2000]\n",
      "loss: 0.264633  [ 1344/ 2000]\n",
      "loss: 0.199361  [ 1984/ 2000]\n",
      "Test Accuracy: 0.9360, Avg Loss: 0.1584\n",
      "\n",
      "Testing model: LargerModel, Optimizer: Adam, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 34.041950  [   64/ 2000]\n",
      "loss: 0.675048  [  704/ 2000]\n",
      "loss: 0.210686  [ 1344/ 2000]\n",
      "loss: 0.475746  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.194906  [   64/ 2000]\n",
      "loss: 0.316968  [  704/ 2000]\n",
      "loss: 0.280487  [ 1344/ 2000]\n",
      "loss: 0.423041  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.311931  [   64/ 2000]\n",
      "loss: 0.259815  [  704/ 2000]\n",
      "loss: 0.283139  [ 1344/ 2000]\n",
      "loss: 0.361971  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.277114  [   64/ 2000]\n",
      "loss: 0.373744  [  704/ 2000]\n",
      "loss: 0.288644  [ 1344/ 2000]\n",
      "loss: 0.200207  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.303231  [   64/ 2000]\n",
      "loss: 0.281543  [  704/ 2000]\n",
      "loss: 0.418765  [ 1344/ 2000]\n",
      "loss: 0.303305  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.248889  [   64/ 2000]\n",
      "loss: 0.255054  [  704/ 2000]\n",
      "loss: 0.373446  [ 1344/ 2000]\n",
      "loss: 0.223972  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.257937  [   64/ 2000]\n",
      "loss: 0.221540  [  704/ 2000]\n",
      "loss: 0.197853  [ 1344/ 2000]\n",
      "loss: 0.257527  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.252544  [   64/ 2000]\n",
      "loss: 0.214165  [  704/ 2000]\n",
      "loss: 0.273793  [ 1344/ 2000]\n",
      "loss: 0.383719  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.321462  [   64/ 2000]\n",
      "loss: 0.296743  [  704/ 2000]\n",
      "loss: 0.309522  [ 1344/ 2000]\n",
      "loss: 0.271850  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.256710  [   64/ 2000]\n",
      "loss: 0.250028  [  704/ 2000]\n",
      "loss: 0.321961  [ 1344/ 2000]\n",
      "loss: 0.233325  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8980, Avg Loss: 0.2138\n",
      "\n",
      "Testing model: LargerModel, Optimizer: Adam, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 11.772068  [   64/ 2000]\n",
      "loss: 4.572403  [  704/ 2000]\n",
      "loss: 0.465033  [ 1344/ 2000]\n",
      "loss: 0.962320  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.296866  [   64/ 2000]\n",
      "loss: 0.863801  [  704/ 2000]\n",
      "loss: 1.026821  [ 1344/ 2000]\n",
      "loss: 0.623708  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.406010  [   64/ 2000]\n",
      "loss: 0.551059  [  704/ 2000]\n",
      "loss: 0.531266  [ 1344/ 2000]\n",
      "loss: 0.560880  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.317490  [   64/ 2000]\n",
      "loss: 0.367852  [  704/ 2000]\n",
      "loss: 0.250826  [ 1344/ 2000]\n",
      "loss: 0.392170  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.518978  [   64/ 2000]\n",
      "loss: 0.323065  [  704/ 2000]\n",
      "loss: 0.416213  [ 1344/ 2000]\n",
      "loss: 0.368836  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.328473  [   64/ 2000]\n",
      "loss: 0.266923  [  704/ 2000]\n",
      "loss: 0.474063  [ 1344/ 2000]\n",
      "loss: 0.285773  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.393530  [   64/ 2000]\n",
      "loss: 0.348431  [  704/ 2000]\n",
      "loss: 0.313163  [ 1344/ 2000]\n",
      "loss: 0.379154  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.317825  [   64/ 2000]\n",
      "loss: 0.284987  [  704/ 2000]\n",
      "loss: 0.389810  [ 1344/ 2000]\n",
      "loss: 0.243468  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.404531  [   64/ 2000]\n",
      "loss: 0.275949  [  704/ 2000]\n",
      "loss: 0.360906  [ 1344/ 2000]\n",
      "loss: 0.326879  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.240742  [   64/ 2000]\n",
      "loss: 0.353197  [  704/ 2000]\n",
      "loss: 0.289196  [ 1344/ 2000]\n",
      "loss: 0.323540  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3026\n",
      "\n",
      "Testing model: LargerModel, Optimizer: RMSprop, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.774637  [   64/ 2000]\n",
      "loss: 0.675998  [  704/ 2000]\n",
      "loss: 0.299426  [ 1344/ 2000]\n",
      "loss: 0.384617  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.514416  [   64/ 2000]\n",
      "loss: 0.315506  [  704/ 2000]\n",
      "loss: 0.414039  [ 1344/ 2000]\n",
      "loss: 0.414832  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.479472  [   64/ 2000]\n",
      "loss: 0.279550  [  704/ 2000]\n",
      "loss: 0.469646  [ 1344/ 2000]\n",
      "loss: 0.386828  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.254771  [   64/ 2000]\n",
      "loss: 0.402856  [  704/ 2000]\n",
      "loss: 0.463053  [ 1344/ 2000]\n",
      "loss: 0.404259  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.377621  [   64/ 2000]\n",
      "loss: 0.449924  [  704/ 2000]\n",
      "loss: 0.367867  [ 1344/ 2000]\n",
      "loss: 0.396723  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.397474  [   64/ 2000]\n",
      "loss: 0.346672  [  704/ 2000]\n",
      "loss: 0.521606  [ 1344/ 2000]\n",
      "loss: 0.381950  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.559293  [   64/ 2000]\n",
      "loss: 0.507807  [  704/ 2000]\n",
      "loss: 0.369719  [ 1344/ 2000]\n",
      "loss: 0.256845  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.391448  [   64/ 2000]\n",
      "loss: 0.339802  [  704/ 2000]\n",
      "loss: 0.449516  [ 1344/ 2000]\n",
      "loss: 0.538283  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.381484  [   64/ 2000]\n",
      "loss: 0.469635  [  704/ 2000]\n",
      "loss: 0.365468  [ 1344/ 2000]\n",
      "loss: 0.383818  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.252671  [   64/ 2000]\n",
      "loss: 0.303197  [  704/ 2000]\n",
      "loss: 0.345935  [ 1344/ 2000]\n",
      "loss: 0.293067  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3028\n",
      "\n",
      "Testing model: LargerModel, Optimizer: RMSprop, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.270822  [   64/ 2000]\n",
      "loss: 0.417296  [  704/ 2000]\n",
      "loss: 0.371790  [ 1344/ 2000]\n",
      "loss: 0.626101  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.291527  [   64/ 2000]\n",
      "loss: 0.452526  [  704/ 2000]\n",
      "loss: 0.418335  [ 1344/ 2000]\n",
      "loss: 0.256335  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.383630  [   64/ 2000]\n",
      "loss: 0.442099  [  704/ 2000]\n",
      "loss: 0.382636  [ 1344/ 2000]\n",
      "loss: 0.292655  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.434146  [   64/ 2000]\n",
      "loss: 0.497575  [  704/ 2000]\n",
      "loss: 0.409112  [ 1344/ 2000]\n",
      "loss: 0.361920  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.272767  [   64/ 2000]\n",
      "loss: 0.423864  [  704/ 2000]\n",
      "loss: 0.251894  [ 1344/ 2000]\n",
      "loss: 0.185839  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.454999  [   64/ 2000]\n",
      "loss: 0.295815  [  704/ 2000]\n",
      "loss: 0.304534  [ 1344/ 2000]\n",
      "loss: 0.304797  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.265112  [   64/ 2000]\n",
      "loss: 0.286367  [  704/ 2000]\n",
      "loss: 0.327492  [ 1344/ 2000]\n",
      "loss: 0.335316  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.244054  [   64/ 2000]\n",
      "loss: 0.343547  [  704/ 2000]\n",
      "loss: 0.304959  [ 1344/ 2000]\n",
      "loss: 0.322890  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.542386  [   64/ 2000]\n",
      "loss: 0.409016  [  704/ 2000]\n",
      "loss: 0.271931  [ 1344/ 2000]\n",
      "loss: 0.163697  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.547492  [   64/ 2000]\n",
      "loss: 0.319326  [  704/ 2000]\n",
      "loss: 0.320903  [ 1344/ 2000]\n",
      "loss: 0.280249  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.4044\n",
      "\n",
      "Testing model: LargerModel, Optimizer: RMSprop, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.858328  [   64/ 2000]\n",
      "loss: 0.417963  [  704/ 2000]\n",
      "loss: 0.372359  [ 1344/ 2000]\n",
      "loss: 0.496200  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.456955  [   64/ 2000]\n",
      "loss: 0.447952  [  704/ 2000]\n",
      "loss: 0.325131  [ 1344/ 2000]\n",
      "loss: 0.389955  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.410407  [   64/ 2000]\n",
      "loss: 0.407860  [  704/ 2000]\n",
      "loss: 0.348026  [ 1344/ 2000]\n",
      "loss: 0.481493  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.296782  [   64/ 2000]\n",
      "loss: 0.441711  [  704/ 2000]\n",
      "loss: 0.353891  [ 1344/ 2000]\n",
      "loss: 0.409748  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.332471  [   64/ 2000]\n",
      "loss: 0.286819  [  704/ 2000]\n",
      "loss: 0.359184  [ 1344/ 2000]\n",
      "loss: 0.267448  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.490330  [   64/ 2000]\n",
      "loss: 0.392928  [  704/ 2000]\n",
      "loss: 0.415910  [ 1344/ 2000]\n",
      "loss: 0.212065  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.369741  [   64/ 2000]\n",
      "loss: 0.232150  [  704/ 2000]\n",
      "loss: 0.284011  [ 1344/ 2000]\n",
      "loss: 0.257065  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.356385  [   64/ 2000]\n",
      "loss: 0.369687  [  704/ 2000]\n",
      "loss: 0.277278  [ 1344/ 2000]\n",
      "loss: 0.321436  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.245586  [   64/ 2000]\n",
      "loss: 0.403792  [  704/ 2000]\n",
      "loss: 0.240876  [ 1344/ 2000]\n",
      "loss: 0.425239  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.443185  [   64/ 2000]\n",
      "loss: 0.437265  [  704/ 2000]\n",
      "loss: 0.225441  [ 1344/ 2000]\n",
      "loss: 0.254209  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8380, Avg Loss: 0.3430\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: SGD, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 31.583405  [   64/ 2000]\n",
      "loss: 0.769616  [  704/ 2000]\n",
      "loss: 0.327602  [ 1344/ 2000]\n",
      "loss: 0.380424  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.354856  [   64/ 2000]\n",
      "loss: 0.516844  [  704/ 2000]\n",
      "loss: 0.147131  [ 1344/ 2000]\n",
      "loss: 0.396963  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.606469  [   64/ 2000]\n",
      "loss: 0.257243  [  704/ 2000]\n",
      "loss: 0.520239  [ 1344/ 2000]\n",
      "loss: 0.483013  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.263634  [   64/ 2000]\n",
      "loss: 0.567768  [  704/ 2000]\n",
      "loss: 0.593802  [ 1344/ 2000]\n",
      "loss: 0.565881  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.543294  [   64/ 2000]\n",
      "loss: 0.588602  [  704/ 2000]\n",
      "loss: 0.541391  [ 1344/ 2000]\n",
      "loss: 0.459834  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.467382  [   64/ 2000]\n",
      "loss: 0.543398  [  704/ 2000]\n",
      "loss: 0.550560  [ 1344/ 2000]\n",
      "loss: 0.520819  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.547599  [   64/ 2000]\n",
      "loss: 0.594018  [  704/ 2000]\n",
      "loss: 0.522113  [ 1344/ 2000]\n",
      "loss: 0.536810  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.574619  [   64/ 2000]\n",
      "loss: 0.482914  [  704/ 2000]\n",
      "loss: 0.497154  [ 1344/ 2000]\n",
      "loss: 0.591406  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.466790  [   64/ 2000]\n",
      "loss: 0.504744  [  704/ 2000]\n",
      "loss: 0.512876  [ 1344/ 2000]\n",
      "loss: 0.428196  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.505672  [   64/ 2000]\n",
      "loss: 0.441310  [  704/ 2000]\n",
      "loss: 0.503126  [ 1344/ 2000]\n",
      "loss: 0.496759  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.5351\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: SGD, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.254952  [   64/ 2000]\n",
      "loss: 3.285838  [  704/ 2000]\n",
      "loss: 1.667859  [ 1344/ 2000]\n",
      "loss: 0.757851  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.247442  [   64/ 2000]\n",
      "loss: 1.101958  [  704/ 2000]\n",
      "loss: 0.573335  [ 1344/ 2000]\n",
      "loss: 0.527082  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.132654  [   64/ 2000]\n",
      "loss: 0.540395  [  704/ 2000]\n",
      "loss: 0.496378  [ 1344/ 2000]\n",
      "loss: 0.911449  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.353788  [   64/ 2000]\n",
      "loss: 0.411904  [  704/ 2000]\n",
      "loss: 0.522004  [ 1344/ 2000]\n",
      "loss: 0.804323  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.485570  [   64/ 2000]\n",
      "loss: 0.497118  [  704/ 2000]\n",
      "loss: 0.472905  [ 1344/ 2000]\n",
      "loss: 0.493237  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.590776  [   64/ 2000]\n",
      "loss: 0.562812  [  704/ 2000]\n",
      "loss: 0.598424  [ 1344/ 2000]\n",
      "loss: 0.335387  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.276286  [   64/ 2000]\n",
      "loss: 0.598857  [  704/ 2000]\n",
      "loss: 0.755809  [ 1344/ 2000]\n",
      "loss: 0.550812  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.291644  [   64/ 2000]\n",
      "loss: 0.441040  [  704/ 2000]\n",
      "loss: 0.474232  [ 1344/ 2000]\n",
      "loss: 0.501809  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.366870  [   64/ 2000]\n",
      "loss: 0.367090  [  704/ 2000]\n",
      "loss: 0.643672  [ 1344/ 2000]\n",
      "loss: 0.465061  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.829837  [   64/ 2000]\n",
      "loss: 0.214893  [  704/ 2000]\n",
      "loss: 0.343803  [ 1344/ 2000]\n",
      "loss: 0.248164  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3900\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: SGD, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.386927  [   64/ 2000]\n",
      "loss: 2.330340  [  704/ 2000]\n",
      "loss: 2.499406  [ 1344/ 2000]\n",
      "loss: 2.749701  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.353383  [   64/ 2000]\n",
      "loss: 1.828374  [  704/ 2000]\n",
      "loss: 3.287685  [ 1344/ 2000]\n",
      "loss: 3.882979  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.441254  [   64/ 2000]\n",
      "loss: 1.830527  [  704/ 2000]\n",
      "loss: 1.228216  [ 1344/ 2000]\n",
      "loss: 1.516907  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.999445  [   64/ 2000]\n",
      "loss: 2.054842  [  704/ 2000]\n",
      "loss: 1.342024  [ 1344/ 2000]\n",
      "loss: 2.642652  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.568666  [   64/ 2000]\n",
      "loss: 1.711229  [  704/ 2000]\n",
      "loss: 1.307685  [ 1344/ 2000]\n",
      "loss: 1.447582  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.490422  [   64/ 2000]\n",
      "loss: 1.046417  [  704/ 2000]\n",
      "loss: 0.834139  [ 1344/ 2000]\n",
      "loss: 2.268801  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.542668  [   64/ 2000]\n",
      "loss: 1.254140  [  704/ 2000]\n",
      "loss: 0.682490  [ 1344/ 2000]\n",
      "loss: 0.686112  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.791579  [   64/ 2000]\n",
      "loss: 0.715608  [  704/ 2000]\n",
      "loss: 0.602326  [ 1344/ 2000]\n",
      "loss: 1.121626  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.415642  [   64/ 2000]\n",
      "loss: 0.591705  [  704/ 2000]\n",
      "loss: 0.797516  [ 1344/ 2000]\n",
      "loss: 0.761434  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.393960  [   64/ 2000]\n",
      "loss: 1.057846  [  704/ 2000]\n",
      "loss: 0.838611  [ 1344/ 2000]\n",
      "loss: 0.978876  [ 1984/ 2000]\n",
      "Test Accuracy: 0.1280, Avg Loss: 2.5290\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: Adam, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.642822  [   64/ 2000]\n",
      "loss: 1.742882  [  704/ 2000]\n",
      "loss: 0.608817  [ 1344/ 2000]\n",
      "loss: 0.464138  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.644129  [   64/ 2000]\n",
      "loss: 0.336656  [  704/ 2000]\n",
      "loss: 0.355863  [ 1344/ 2000]\n",
      "loss: 0.256942  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.231951  [   64/ 2000]\n",
      "loss: 0.309235  [  704/ 2000]\n",
      "loss: 0.448672  [ 1344/ 2000]\n",
      "loss: 0.412664  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.523361  [   64/ 2000]\n",
      "loss: 0.369598  [  704/ 2000]\n",
      "loss: 0.238271  [ 1344/ 2000]\n",
      "loss: 0.295864  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.141946  [   64/ 2000]\n",
      "loss: 0.274730  [  704/ 2000]\n",
      "loss: 0.311550  [ 1344/ 2000]\n",
      "loss: 0.251060  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.254973  [   64/ 2000]\n",
      "loss: 0.223841  [  704/ 2000]\n",
      "loss: 0.273062  [ 1344/ 2000]\n",
      "loss: 0.283670  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.288443  [   64/ 2000]\n",
      "loss: 0.418601  [  704/ 2000]\n",
      "loss: 0.240203  [ 1344/ 2000]\n",
      "loss: 0.257273  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.200754  [   64/ 2000]\n",
      "loss: 0.379574  [  704/ 2000]\n",
      "loss: 0.323081  [ 1344/ 2000]\n",
      "loss: 0.284840  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.303264  [   64/ 2000]\n",
      "loss: 0.243943  [  704/ 2000]\n",
      "loss: 0.161741  [ 1344/ 2000]\n",
      "loss: 0.241176  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.269084  [   64/ 2000]\n",
      "loss: 0.246749  [  704/ 2000]\n",
      "loss: 0.141946  [ 1344/ 2000]\n",
      "loss: 0.161091  [ 1984/ 2000]\n",
      "Test Accuracy: 0.9060, Avg Loss: 0.1981\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: Adam, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 11.075327  [   64/ 2000]\n",
      "loss: 3.507704  [  704/ 2000]\n",
      "loss: 2.081875  [ 1344/ 2000]\n",
      "loss: 1.195329  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.062366  [   64/ 2000]\n",
      "loss: 1.427761  [  704/ 2000]\n",
      "loss: 2.300576  [ 1344/ 2000]\n",
      "loss: 1.428106  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.020167  [   64/ 2000]\n",
      "loss: 0.998317  [  704/ 2000]\n",
      "loss: 0.979041  [ 1344/ 2000]\n",
      "loss: 1.265698  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.180992  [   64/ 2000]\n",
      "loss: 0.738543  [  704/ 2000]\n",
      "loss: 0.903612  [ 1344/ 2000]\n",
      "loss: 0.912996  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.946877  [   64/ 2000]\n",
      "loss: 0.614712  [  704/ 2000]\n",
      "loss: 1.413883  [ 1344/ 2000]\n",
      "loss: 0.706732  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.690780  [   64/ 2000]\n",
      "loss: 0.375222  [  704/ 2000]\n",
      "loss: 0.895025  [ 1344/ 2000]\n",
      "loss: 0.545028  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.627972  [   64/ 2000]\n",
      "loss: 0.834261  [  704/ 2000]\n",
      "loss: 0.471991  [ 1344/ 2000]\n",
      "loss: 0.442378  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.664591  [   64/ 2000]\n",
      "loss: 0.678101  [  704/ 2000]\n",
      "loss: 0.410200  [ 1344/ 2000]\n",
      "loss: 0.528895  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.630347  [   64/ 2000]\n",
      "loss: 0.702866  [  704/ 2000]\n",
      "loss: 0.710007  [ 1344/ 2000]\n",
      "loss: 0.339266  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.513115  [   64/ 2000]\n",
      "loss: 0.429217  [  704/ 2000]\n",
      "loss: 0.715620  [ 1344/ 2000]\n",
      "loss: 0.493005  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3780\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: Adam, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 9.339555  [   64/ 2000]\n",
      "loss: 7.101451  [  704/ 2000]\n",
      "loss: 8.757219  [ 1344/ 2000]\n",
      "loss: 6.431421  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 7.435354  [   64/ 2000]\n",
      "loss: 3.770449  [  704/ 2000]\n",
      "loss: 6.304616  [ 1344/ 2000]\n",
      "loss: 4.531236  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 6.350884  [   64/ 2000]\n",
      "loss: 4.808864  [  704/ 2000]\n",
      "loss: 3.795256  [ 1344/ 2000]\n",
      "loss: 4.585289  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.511721  [   64/ 2000]\n",
      "loss: 6.516099  [  704/ 2000]\n",
      "loss: 7.575948  [ 1344/ 2000]\n",
      "loss: 3.813456  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.116348  [   64/ 2000]\n",
      "loss: 6.559869  [  704/ 2000]\n",
      "loss: 2.549879  [ 1344/ 2000]\n",
      "loss: 4.345679  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.192729  [   64/ 2000]\n",
      "loss: 5.213089  [  704/ 2000]\n",
      "loss: 4.214986  [ 1344/ 2000]\n",
      "loss: 4.360693  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.105433  [   64/ 2000]\n",
      "loss: 2.325925  [  704/ 2000]\n",
      "loss: 2.613405  [ 1344/ 2000]\n",
      "loss: 2.561727  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.687855  [   64/ 2000]\n",
      "loss: 3.642622  [  704/ 2000]\n",
      "loss: 3.651292  [ 1344/ 2000]\n",
      "loss: 3.168750  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.876081  [   64/ 2000]\n",
      "loss: 1.601094  [  704/ 2000]\n",
      "loss: 3.271393  [ 1344/ 2000]\n",
      "loss: 3.130892  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.598910  [   64/ 2000]\n",
      "loss: 2.185290  [  704/ 2000]\n",
      "loss: 1.172746  [ 1344/ 2000]\n",
      "loss: 2.401072  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 1.8389\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: RMSprop, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 8.567250  [   64/ 2000]\n",
      "loss: 0.386817  [  704/ 2000]\n",
      "loss: 0.377551  [ 1344/ 2000]\n",
      "loss: 0.313154  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.331432  [   64/ 2000]\n",
      "loss: 0.191450  [  704/ 2000]\n",
      "loss: 0.321088  [ 1344/ 2000]\n",
      "loss: 0.262314  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.392172  [   64/ 2000]\n",
      "loss: 0.259218  [  704/ 2000]\n",
      "loss: 0.397017  [ 1344/ 2000]\n",
      "loss: 0.281009  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.296703  [   64/ 2000]\n",
      "loss: 0.185872  [  704/ 2000]\n",
      "loss: 0.233322  [ 1344/ 2000]\n",
      "loss: 0.515958  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.314273  [   64/ 2000]\n",
      "loss: 0.191402  [  704/ 2000]\n",
      "loss: 0.286348  [ 1344/ 2000]\n",
      "loss: 0.196078  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.151417  [   64/ 2000]\n",
      "loss: 0.286739  [  704/ 2000]\n",
      "loss: 0.177074  [ 1344/ 2000]\n",
      "loss: 0.185402  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.286025  [   64/ 2000]\n",
      "loss: 0.284333  [  704/ 2000]\n",
      "loss: 0.253691  [ 1344/ 2000]\n",
      "loss: 0.210916  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.285105  [   64/ 2000]\n",
      "loss: 0.183182  [  704/ 2000]\n",
      "loss: 0.321925  [ 1344/ 2000]\n",
      "loss: 0.322849  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.318725  [   64/ 2000]\n",
      "loss: 0.176873  [  704/ 2000]\n",
      "loss: 0.231080  [ 1344/ 2000]\n",
      "loss: 0.232279  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.435967  [   64/ 2000]\n",
      "loss: 0.234999  [  704/ 2000]\n",
      "loss: 0.301006  [ 1344/ 2000]\n",
      "loss: 0.112915  [ 1984/ 2000]\n",
      "Test Accuracy: 0.9260, Avg Loss: 0.1645\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: RMSprop, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 8.225000  [   64/ 2000]\n",
      "loss: 4.339271  [  704/ 2000]\n",
      "loss: 3.432216  [ 1344/ 2000]\n",
      "loss: 2.247866  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.302985  [   64/ 2000]\n",
      "loss: 1.215780  [  704/ 2000]\n",
      "loss: 2.203534  [ 1344/ 2000]\n",
      "loss: 0.842130  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.971418  [   64/ 2000]\n",
      "loss: 2.066082  [  704/ 2000]\n",
      "loss: 0.980422  [ 1344/ 2000]\n",
      "loss: 1.418468  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.186403  [   64/ 2000]\n",
      "loss: 1.511996  [  704/ 2000]\n",
      "loss: 0.463420  [ 1344/ 2000]\n",
      "loss: 0.850116  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.747644  [   64/ 2000]\n",
      "loss: 0.635914  [  704/ 2000]\n",
      "loss: 0.668616  [ 1344/ 2000]\n",
      "loss: 1.212219  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.456139  [   64/ 2000]\n",
      "loss: 0.638533  [  704/ 2000]\n",
      "loss: 0.478905  [ 1344/ 2000]\n",
      "loss: 0.508114  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.957044  [   64/ 2000]\n",
      "loss: 1.183018  [  704/ 2000]\n",
      "loss: 1.058906  [ 1344/ 2000]\n",
      "loss: 1.143694  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.527616  [   64/ 2000]\n",
      "loss: 1.821935  [  704/ 2000]\n",
      "loss: 0.852454  [ 1344/ 2000]\n",
      "loss: 0.780692  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.078046  [   64/ 2000]\n",
      "loss: 1.442562  [  704/ 2000]\n",
      "loss: 0.689916  [ 1344/ 2000]\n",
      "loss: 0.502326  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.556121  [   64/ 2000]\n",
      "loss: 0.413600  [  704/ 2000]\n",
      "loss: 0.444734  [ 1344/ 2000]\n",
      "loss: 0.448550  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3604\n",
      "\n",
      "Testing model: ModelWithDropout, Optimizer: RMSprop, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 27.784472  [   64/ 2000]\n",
      "loss: 7.378275  [  704/ 2000]\n",
      "loss: 8.700635  [ 1344/ 2000]\n",
      "loss: 6.012923  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.168835  [   64/ 2000]\n",
      "loss: 3.765509  [  704/ 2000]\n",
      "loss: 3.675304  [ 1344/ 2000]\n",
      "loss: 4.706440  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.688760  [   64/ 2000]\n",
      "loss: 1.483434  [  704/ 2000]\n",
      "loss: 4.748977  [ 1344/ 2000]\n",
      "loss: 4.610590  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 5.137232  [   64/ 2000]\n",
      "loss: 4.187592  [  704/ 2000]\n",
      "loss: 4.102098  [ 1344/ 2000]\n",
      "loss: 3.254253  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.878787  [   64/ 2000]\n",
      "loss: 4.458572  [  704/ 2000]\n",
      "loss: 4.953468  [ 1344/ 2000]\n",
      "loss: 4.997622  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 5.894529  [   64/ 2000]\n",
      "loss: 5.311069  [  704/ 2000]\n",
      "loss: 3.588417  [ 1344/ 2000]\n",
      "loss: 2.442087  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.796583  [   64/ 2000]\n",
      "loss: 3.542344  [  704/ 2000]\n",
      "loss: 4.862096  [ 1344/ 2000]\n",
      "loss: 2.827626  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.857769  [   64/ 2000]\n",
      "loss: 0.972853  [  704/ 2000]\n",
      "loss: 3.557663  [ 1344/ 2000]\n",
      "loss: 2.328536  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.090470  [   64/ 2000]\n",
      "loss: 2.093843  [  704/ 2000]\n",
      "loss: 4.681969  [ 1344/ 2000]\n",
      "loss: 2.306326  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.459072  [   64/ 2000]\n",
      "loss: 1.247960  [  704/ 2000]\n",
      "loss: 3.121986  [ 1344/ 2000]\n",
      "loss: 2.305062  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 1.4267\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: SGD, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 17.573891  [   64/ 2000]\n",
      "loss: 19469890.000000  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss:     nan  [   64/ 2000]\n",
      "loss:     nan  [  704/ 2000]\n",
      "loss:     nan  [ 1344/ 2000]\n",
      "loss:     nan  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: nan\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: SGD, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.036607  [   64/ 2000]\n",
      "loss: 4.234818  [  704/ 2000]\n",
      "loss: 0.310507  [ 1344/ 2000]\n",
      "loss: 1.579796  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.645415  [   64/ 2000]\n",
      "loss: 0.341678  [  704/ 2000]\n",
      "loss: 0.351517  [ 1344/ 2000]\n",
      "loss: 0.373750  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.562057  [   64/ 2000]\n",
      "loss: 0.271572  [  704/ 2000]\n",
      "loss: 0.314192  [ 1344/ 2000]\n",
      "loss: 0.228341  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.358258  [   64/ 2000]\n",
      "loss: 0.333905  [  704/ 2000]\n",
      "loss: 0.328499  [ 1344/ 2000]\n",
      "loss: 0.411955  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.385416  [   64/ 2000]\n",
      "loss: 0.374731  [  704/ 2000]\n",
      "loss: 0.356328  [ 1344/ 2000]\n",
      "loss: 0.291277  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.302985  [   64/ 2000]\n",
      "loss: 0.429954  [  704/ 2000]\n",
      "loss: 0.275665  [ 1344/ 2000]\n",
      "loss: 0.351559  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.158389  [   64/ 2000]\n",
      "loss: 0.359351  [  704/ 2000]\n",
      "loss: 0.269450  [ 1344/ 2000]\n",
      "loss: 0.321255  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.339250  [   64/ 2000]\n",
      "loss: 0.343438  [  704/ 2000]\n",
      "loss: 0.430598  [ 1344/ 2000]\n",
      "loss: 0.268335  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.285789  [   64/ 2000]\n",
      "loss: 0.362068  [  704/ 2000]\n",
      "loss: 0.499729  [ 1344/ 2000]\n",
      "loss: 0.310421  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.377865  [   64/ 2000]\n",
      "loss: 0.278983  [  704/ 2000]\n",
      "loss: 0.351979  [ 1344/ 2000]\n",
      "loss: 0.617333  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3290\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: SGD, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.440541  [   64/ 2000]\n",
      "loss: 0.378374  [  704/ 2000]\n",
      "loss: 0.434119  [ 1344/ 2000]\n",
      "loss: 0.459259  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.411134  [   64/ 2000]\n",
      "loss: 0.394943  [  704/ 2000]\n",
      "loss: 0.262284  [ 1344/ 2000]\n",
      "loss: 0.359842  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.658943  [   64/ 2000]\n",
      "loss: 0.434411  [  704/ 2000]\n",
      "loss: 0.357156  [ 1344/ 2000]\n",
      "loss: 0.554406  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.394856  [   64/ 2000]\n",
      "loss: 0.293283  [  704/ 2000]\n",
      "loss: 0.374914  [ 1344/ 2000]\n",
      "loss: 0.297302  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.488454  [   64/ 2000]\n",
      "loss: 0.401797  [  704/ 2000]\n",
      "loss: 0.405600  [ 1344/ 2000]\n",
      "loss: 0.485549  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.396962  [   64/ 2000]\n",
      "loss: 0.341730  [  704/ 2000]\n",
      "loss: 0.339489  [ 1344/ 2000]\n",
      "loss: 0.298816  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.480831  [   64/ 2000]\n",
      "loss: 0.421918  [  704/ 2000]\n",
      "loss: 0.466601  [ 1344/ 2000]\n",
      "loss: 0.340985  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.479944  [   64/ 2000]\n",
      "loss: 0.443195  [  704/ 2000]\n",
      "loss: 0.496837  [ 1344/ 2000]\n",
      "loss: 0.631623  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.364555  [   64/ 2000]\n",
      "loss: 0.511847  [  704/ 2000]\n",
      "loss: 0.343886  [ 1344/ 2000]\n",
      "loss: 0.375595  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.351170  [   64/ 2000]\n",
      "loss: 0.349209  [  704/ 2000]\n",
      "loss: 0.277297  [ 1344/ 2000]\n",
      "loss: 0.501624  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8360, Avg Loss: 0.3810\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: Adam, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.275347  [   64/ 2000]\n",
      "loss: 2.801402  [  704/ 2000]\n",
      "loss: 0.726446  [ 1344/ 2000]\n",
      "loss: 0.463866  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.655622  [   64/ 2000]\n",
      "loss: 0.374084  [  704/ 2000]\n",
      "loss: 0.257616  [ 1344/ 2000]\n",
      "loss: 0.238777  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.326169  [   64/ 2000]\n",
      "loss: 0.336192  [  704/ 2000]\n",
      "loss: 0.399139  [ 1344/ 2000]\n",
      "loss: 0.401751  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.416182  [   64/ 2000]\n",
      "loss: 0.266694  [  704/ 2000]\n",
      "loss: 0.275978  [ 1344/ 2000]\n",
      "loss: 0.227268  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.385421  [   64/ 2000]\n",
      "loss: 0.223932  [  704/ 2000]\n",
      "loss: 0.209161  [ 1344/ 2000]\n",
      "loss: 0.267906  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.272609  [   64/ 2000]\n",
      "loss: 0.284663  [  704/ 2000]\n",
      "loss: 0.218808  [ 1344/ 2000]\n",
      "loss: 0.186909  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.250676  [   64/ 2000]\n",
      "loss: 0.178063  [  704/ 2000]\n",
      "loss: 0.171443  [ 1344/ 2000]\n",
      "loss: 0.183362  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.230306  [   64/ 2000]\n",
      "loss: 0.350024  [  704/ 2000]\n",
      "loss: 0.304969  [ 1344/ 2000]\n",
      "loss: 0.274136  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.192552  [   64/ 2000]\n",
      "loss: 0.160768  [  704/ 2000]\n",
      "loss: 0.244133  [ 1344/ 2000]\n",
      "loss: 0.093172  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.122827  [   64/ 2000]\n",
      "loss: 0.165479  [  704/ 2000]\n",
      "loss: 0.165023  [ 1344/ 2000]\n",
      "loss: 0.251939  [ 1984/ 2000]\n",
      "Test Accuracy: 0.9260, Avg Loss: 0.1671\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: Adam, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 47.378151  [   64/ 2000]\n",
      "loss: 3.953308  [  704/ 2000]\n",
      "loss: 5.032899  [ 1344/ 2000]\n",
      "loss: 4.917504  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.221501  [   64/ 2000]\n",
      "loss: 0.865596  [  704/ 2000]\n",
      "loss: 0.483521  [ 1344/ 2000]\n",
      "loss: 0.419563  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.434258  [   64/ 2000]\n",
      "loss: 0.305988  [  704/ 2000]\n",
      "loss: 0.414028  [ 1344/ 2000]\n",
      "loss: 0.335843  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.376963  [   64/ 2000]\n",
      "loss: 0.214512  [  704/ 2000]\n",
      "loss: 0.278914  [ 1344/ 2000]\n",
      "loss: 0.307087  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.253446  [   64/ 2000]\n",
      "loss: 0.355735  [  704/ 2000]\n",
      "loss: 0.259658  [ 1344/ 2000]\n",
      "loss: 0.326918  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.252971  [   64/ 2000]\n",
      "loss: 0.264043  [  704/ 2000]\n",
      "loss: 0.234827  [ 1344/ 2000]\n",
      "loss: 0.264626  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.158354  [   64/ 2000]\n",
      "loss: 0.109053  [  704/ 2000]\n",
      "loss: 0.231266  [ 1344/ 2000]\n",
      "loss: 0.205515  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.188323  [   64/ 2000]\n",
      "loss: 0.257229  [  704/ 2000]\n",
      "loss: 0.158797  [ 1344/ 2000]\n",
      "loss: 0.186399  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.183786  [   64/ 2000]\n",
      "loss: 0.199325  [  704/ 2000]\n",
      "loss: 0.216382  [ 1344/ 2000]\n",
      "loss: 0.123132  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.211622  [   64/ 2000]\n",
      "loss: 0.229725  [  704/ 2000]\n",
      "loss: 0.165369  [ 1344/ 2000]\n",
      "loss: 0.200869  [ 1984/ 2000]\n",
      "Test Accuracy: 0.9080, Avg Loss: 0.1774\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: Adam, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.544377  [   64/ 2000]\n",
      "loss: 3.438950  [  704/ 2000]\n",
      "loss: 3.143345  [ 1344/ 2000]\n",
      "loss: 2.175480  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.075287  [   64/ 2000]\n",
      "loss: 1.610626  [  704/ 2000]\n",
      "loss: 0.681749  [ 1344/ 2000]\n",
      "loss: 0.493999  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.663576  [   64/ 2000]\n",
      "loss: 0.305554  [  704/ 2000]\n",
      "loss: 0.425036  [ 1344/ 2000]\n",
      "loss: 0.489867  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.541879  [   64/ 2000]\n",
      "loss: 0.524150  [  704/ 2000]\n",
      "loss: 0.496474  [ 1344/ 2000]\n",
      "loss: 0.632249  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.628645  [   64/ 2000]\n",
      "loss: 0.467215  [  704/ 2000]\n",
      "loss: 0.591493  [ 1344/ 2000]\n",
      "loss: 0.476086  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.333216  [   64/ 2000]\n",
      "loss: 0.482062  [  704/ 2000]\n",
      "loss: 0.511722  [ 1344/ 2000]\n",
      "loss: 0.669741  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.441517  [   64/ 2000]\n",
      "loss: 0.578553  [  704/ 2000]\n",
      "loss: 0.302473  [ 1344/ 2000]\n",
      "loss: 0.479927  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.509558  [   64/ 2000]\n",
      "loss: 0.593801  [  704/ 2000]\n",
      "loss: 0.532541  [ 1344/ 2000]\n",
      "loss: 0.571671  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.409077  [   64/ 2000]\n",
      "loss: 0.458361  [  704/ 2000]\n",
      "loss: 0.360986  [ 1344/ 2000]\n",
      "loss: 0.420518  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.385484  [   64/ 2000]\n",
      "loss: 0.407470  [  704/ 2000]\n",
      "loss: 0.435969  [ 1344/ 2000]\n",
      "loss: 0.501797  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.4109\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: RMSprop, LR: 0.01\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 50.871288  [   64/ 2000]\n",
      "loss: 1.392661  [  704/ 2000]\n",
      "loss: 4.165061  [ 1344/ 2000]\n",
      "loss: 0.250329  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.134013  [   64/ 2000]\n",
      "loss: 0.945438  [  704/ 2000]\n",
      "loss: 0.277710  [ 1344/ 2000]\n",
      "loss: 0.369048  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.421891  [   64/ 2000]\n",
      "loss: 0.488171  [  704/ 2000]\n",
      "loss: 0.241264  [ 1344/ 2000]\n",
      "loss: 0.423618  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.278231  [   64/ 2000]\n",
      "loss: 0.190662  [  704/ 2000]\n",
      "loss: 0.282502  [ 1344/ 2000]\n",
      "loss: 0.340006  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.476893  [   64/ 2000]\n",
      "loss: 0.381219  [  704/ 2000]\n",
      "loss: 0.297860  [ 1344/ 2000]\n",
      "loss: 0.326042  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.139082  [   64/ 2000]\n",
      "loss: 0.215490  [  704/ 2000]\n",
      "loss: 0.154675  [ 1344/ 2000]\n",
      "loss: 0.170026  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.500904  [   64/ 2000]\n",
      "loss: 0.196020  [  704/ 2000]\n",
      "loss: 0.221879  [ 1344/ 2000]\n",
      "loss: 0.288937  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.263426  [   64/ 2000]\n",
      "loss: 0.207246  [  704/ 2000]\n",
      "loss: 0.472200  [ 1344/ 2000]\n",
      "loss: 0.282818  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.352100  [   64/ 2000]\n",
      "loss: 1.582279  [  704/ 2000]\n",
      "loss: 0.300907  [ 1344/ 2000]\n",
      "loss: 0.209796  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.200094  [   64/ 2000]\n",
      "loss: 0.175303  [  704/ 2000]\n",
      "loss: 0.296944  [ 1344/ 2000]\n",
      "loss: 0.597901  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.3009\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: RMSprop, LR: 0.001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.623223  [   64/ 2000]\n",
      "loss: 2.215908  [  704/ 2000]\n",
      "loss: 0.525721  [ 1344/ 2000]\n",
      "loss: 0.468795  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.526219  [   64/ 2000]\n",
      "loss: 0.348377  [  704/ 2000]\n",
      "loss: 1.359433  [ 1344/ 2000]\n",
      "loss: 0.673537  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.756167  [   64/ 2000]\n",
      "loss: 0.344583  [  704/ 2000]\n",
      "loss: 0.442851  [ 1344/ 2000]\n",
      "loss: 1.018185  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.548512  [   64/ 2000]\n",
      "loss: 0.477133  [  704/ 2000]\n",
      "loss: 0.162432  [ 1344/ 2000]\n",
      "loss: 0.272381  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.211235  [   64/ 2000]\n",
      "loss: 0.173951  [  704/ 2000]\n",
      "loss: 1.529176  [ 1344/ 2000]\n",
      "loss: 0.192739  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.476219  [   64/ 2000]\n",
      "loss: 0.239542  [  704/ 2000]\n",
      "loss: 0.827252  [ 1344/ 2000]\n",
      "loss: 0.443226  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.398409  [   64/ 2000]\n",
      "loss: 0.721608  [  704/ 2000]\n",
      "loss: 0.502312  [ 1344/ 2000]\n",
      "loss: 0.163011  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.159070  [   64/ 2000]\n",
      "loss: 0.792784  [  704/ 2000]\n",
      "loss: 0.383117  [ 1344/ 2000]\n",
      "loss: 0.839132  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.583215  [   64/ 2000]\n",
      "loss: 0.270636  [  704/ 2000]\n",
      "loss: 0.374097  [ 1344/ 2000]\n",
      "loss: 0.298661  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.257230  [   64/ 2000]\n",
      "loss: 0.492483  [  704/ 2000]\n",
      "loss: 0.710976  [ 1344/ 2000]\n",
      "loss: 0.412522  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8880, Avg Loss: 0.2156\n",
      "\n",
      "Testing model: ModelWithLeakyReLU, Optimizer: RMSprop, LR: 0.0001\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.093297  [   64/ 2000]\n",
      "loss: 0.727606  [  704/ 2000]\n",
      "loss: 0.929848  [ 1344/ 2000]\n",
      "loss: 0.832326  [ 1984/ 2000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.364528  [   64/ 2000]\n",
      "loss: 0.662633  [  704/ 2000]\n",
      "loss: 0.729189  [ 1344/ 2000]\n",
      "loss: 0.412005  [ 1984/ 2000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.476714  [   64/ 2000]\n",
      "loss: 0.425254  [  704/ 2000]\n",
      "loss: 0.674129  [ 1344/ 2000]\n",
      "loss: 0.384050  [ 1984/ 2000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.603074  [   64/ 2000]\n",
      "loss: 0.363020  [  704/ 2000]\n",
      "loss: 0.197355  [ 1344/ 2000]\n",
      "loss: 0.526078  [ 1984/ 2000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.239963  [   64/ 2000]\n",
      "loss: 0.455335  [  704/ 2000]\n",
      "loss: 0.382027  [ 1344/ 2000]\n",
      "loss: 0.386964  [ 1984/ 2000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.378188  [   64/ 2000]\n",
      "loss: 0.519460  [  704/ 2000]\n",
      "loss: 0.398954  [ 1344/ 2000]\n",
      "loss: 0.343232  [ 1984/ 2000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.398714  [   64/ 2000]\n",
      "loss: 0.521330  [  704/ 2000]\n",
      "loss: 0.537121  [ 1344/ 2000]\n",
      "loss: 0.390873  [ 1984/ 2000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.532079  [   64/ 2000]\n",
      "loss: 0.410576  [  704/ 2000]\n",
      "loss: 0.463316  [ 1344/ 2000]\n",
      "loss: 0.431632  [ 1984/ 2000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.496487  [   64/ 2000]\n",
      "loss: 0.387165  [  704/ 2000]\n",
      "loss: 0.389573  [ 1344/ 2000]\n",
      "loss: 0.400770  [ 1984/ 2000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.393142  [   64/ 2000]\n",
      "loss: 0.425009  [  704/ 2000]\n",
      "loss: 0.370558  [ 1344/ 2000]\n",
      "loss: 0.438797  [ 1984/ 2000]\n",
      "Test Accuracy: 0.8720, Avg Loss: 0.4468\n",
      "\n",
      "Best Model Results:\n",
      "Model: LargerModel\n",
      "Optimizer: Adam\n",
      "Learning Rate: 0.01\n",
      "Accuracy: 0.9360\n"
     ]
    }
   ],
   "source": [
    "# Define a list of models, optimizers and learning rates\n",
    "models = [NeuralNetwork, LargerModel, ModelWithDropout, ModelWithLeakyReLU]\n",
    "optimizers = [torch.optim.SGD, torch.optim.Adam, torch.optim.RMSprop]\n",
    "learning_rates = [1e-2, 1e-3, 1e-4]\n",
    "\n",
    "# Variables to keep the best results\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_params = {}\n",
    "epochs = 10\n",
    "\n",
    "# Cycle for experiments\n",
    "for model_class in models:\n",
    "    for opt_class in optimizers:\n",
    "        for lr in learning_rates:\n",
    "            print(f\"\\nTesting model: {model_class.__name__}, Optimizer: {opt_class.__name__}, LR: {lr}\")\n",
    "\n",
    "            # Initialization of the model and the optimizer\n",
    "            model = model_class().to(device)\n",
    "            optimizer = opt_class(model.parameters(), lr=lr)\n",
    "\n",
    "            # Model training\n",
    "            for t in range(epochs):\n",
    "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "\n",
    "            # Model testing\n",
    "            size = len(test_dataloader.dataset)\n",
    "            num_batches = len(test_dataloader)\n",
    "            test_loss, correct = 0, 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for X, y in test_dataloader:\n",
    "                    pred = model(X)\n",
    "                    test_loss += loss_fn(pred, y).item()\n",
    "                    binary_pred = torch.where(pred.sigmoid() > 0.5, 1.0, 0.0)\n",
    "                    correct += (binary_pred == y).type(torch.float).sum().item()\n",
    "\n",
    "            test_loss /= num_batches\n",
    "            accuracy = correct / size\n",
    "            print(f\"Test Accuracy: {accuracy:.4f}, Avg Loss: {test_loss:.4f}\")\n",
    "            \n",
    "\n",
    "            # Keep the best model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = model\n",
    "                best_params = {\n",
    "                    \"model\": model_class.__name__,\n",
    "                    \"optimizer\": opt_class.__name__,\n",
    "                    \"learning_rate\": lr,\n",
    "                }\n",
    "\n",
    "print(\"\\nBest Model Results:\")\n",
    "print(f\"Model: {best_params['model']}\")\n",
    "print(f\"Optimizer: {best_params['optimizer']}\")\n",
    "print(f\"Learning Rate: {best_params['learning_rate']}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Saving the best model\n",
    "torch.save(best_model.state_dict(), \"best_weather_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4fbf0-f744-412e-b501-9f3fc8506e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (ipykernel)",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
