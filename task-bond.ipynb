{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e006b9c4-af66-439e-963d-b5a387e1d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# Мапа для цільових індексів\n",
    "index_map = {\n",
    "    0: \"AGG\",\n",
    "    1: \"BIL\",\n",
    "    2: \"BND\",\n",
    "    3: \"EDV\",\n",
    "    4: \"IEF\",\n",
    "    5: \"IEI\",\n",
    "    6: \"SHV\",\n",
    "    7: \"SHY\",\n",
    "    8: \"TLH\",\n",
    "    9: \"TLT\",\n",
    "    10: \"VGIT\"\n",
    "}\n",
    "\n",
    "# Dataset клас\n",
    "class BondDataset(Dataset):\n",
    "    def __init__(self, lag, target=0, file_path=\"bond_etfs.csv\", transform=None):\n",
    "        self.lag = lag\n",
    "        self.target = target\n",
    "        self.records = np.genfromtxt(\n",
    "            file_path,\n",
    "            delimiter=\",\",\n",
    "            skip_header=1,\n",
    "            usecols=(1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12)\n",
    "        ).astype(np.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records) - self.lag\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        records = self.records[idx:idx + self.lag + 1]\n",
    "        x = torch.from_numpy(records[:-1])\n",
    "        y = torch.from_numpy(np.atleast_1d(records[-1][self.target] - records[-2][self.target]))\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43be92cf-5912-4856-bd6f-c46e7b8bf552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718d4d22-4276-431a-b35b-66535e45c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_dataset = BondDataset(lag=15, target=1)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6904ed-1818-42fa-a81c-d55db609e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, lag):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(lag * 11, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "# LSTM модель\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, lag, input_dim=11, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return self.fc(hidden[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4778098-729c-46d7-801d-5426fed9e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # Обчислення метрик\n",
    "    mse = np.mean((all_preds - all_labels) ** 2)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    r2 = r2_score(all_labels, all_preds)\n",
    "    \n",
    "    return test_loss / len(dataloader), mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1bc1ac-7edb-4a4f-bd9b-d8c5387be854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Model=NeuralNetwork, BatchSize=32, LR=0.0001, Lag=5\n",
      "Testing: Model=NeuralNetwork, BatchSize=32, LR=0.0001, Lag=15\n",
      "Testing: Model=NeuralNetwork, BatchSize=32, LR=0.001, Lag=5\n",
      "Testing: Model=NeuralNetwork, BatchSize=32, LR=0.001, Lag=15\n",
      "Testing: Model=NeuralNetwork, BatchSize=64, LR=0.0001, Lag=5\n",
      "Testing: Model=NeuralNetwork, BatchSize=64, LR=0.0001, Lag=15\n",
      "Testing: Model=NeuralNetwork, BatchSize=64, LR=0.001, Lag=5\n",
      "Testing: Model=NeuralNetwork, BatchSize=64, LR=0.001, Lag=15\n",
      "Testing: Model=LSTMModel, BatchSize=32, LR=0.0001, Lag=5\n",
      "Testing: Model=LSTMModel, BatchSize=32, LR=0.0001, Lag=15\n",
      "Testing: Model=LSTMModel, BatchSize=32, LR=0.001, Lag=5\n",
      "Testing: Model=LSTMModel, BatchSize=32, LR=0.001, Lag=15\n",
      "Testing: Model=LSTMModel, BatchSize=64, LR=0.0001, Lag=5\n",
      "Testing: Model=LSTMModel, BatchSize=64, LR=0.0001, Lag=15\n",
      "Testing: Model=LSTMModel, BatchSize=64, LR=0.001, Lag=5\n",
      "Testing: Model=LSTMModel, BatchSize=64, LR=0.001, Lag=15\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"model\": [\"NeuralNetwork\", \"LSTMModel\"],\n",
    "    \"batch_size\": [32, 64],\n",
    "    \"learning_rate\": [1e-4, 1e-3],\n",
    "    \"lag\": [5, 15]\n",
    "}\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Основний цикл експериментів\n",
    "results = []\n",
    "for params in param_combinations:\n",
    "    model_type, batch_size, learning_rate, lag = params\n",
    "    print(f\"Testing: Model={model_type}, BatchSize={batch_size}, LR={learning_rate}, Lag={lag}\")\n",
    "\n",
    "    # Ініціалізація датасету\n",
    "    dataset = BondDataset(lag=lag, target=1)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Ініціалізація моделі\n",
    "    if model_type == \"NeuralNetwork\":\n",
    "        model = NeuralNetwork(lag).to(device)\n",
    "    elif model_type == \"LSTMModel\":\n",
    "        model = LSTMModel(lag).to(device)\n",
    "\n",
    "    # Ініціалізація оптимізатора та функції втрат\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5062ca6-be33-4cfc-bf61-0ede250a4e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Results: \n",
      "Test Loss: 0.0028\n",
      "MSE: 0.0027\n",
      "MAE: 0.0213\n",
      "R²: -0.0593\n",
      "----------------------------------------\n",
      "Epoch 2 Results: \n",
      "Test Loss: 0.0027\n",
      "MSE: 0.0027\n",
      "MAE: 0.0196\n",
      "R²: -0.0386\n",
      "----------------------------------------\n",
      "Epoch 3 Results: \n",
      "Test Loss: 0.0027\n",
      "MSE: 0.0026\n",
      "MAE: 0.0191\n",
      "R²: -0.0063\n",
      "----------------------------------------\n",
      "Epoch 4 Results: \n",
      "Test Loss: 0.0027\n",
      "MSE: 0.0026\n",
      "MAE: 0.0214\n",
      "R²: -0.0056\n",
      "----------------------------------------\n",
      "Epoch 5 Results: \n",
      "Test Loss: 0.0028\n",
      "MSE: 0.0027\n",
      "MAE: 0.0268\n",
      "R²: -0.0524\n",
      "----------------------------------------\n",
      "Results saved to 'experiment_results.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    " for epoch in range(5):  # Кількість епох можна змінити\n",
    "        train_loop(train_loader, model, loss_fn, optimizer, device)\n",
    "\n",
    "    # Тестування\n",
    "        test_loss, mse, mae, r2 = test_loop(test_loader, model, loss_fn, device)\n",
    "\n",
    "      # Виведення результатів кожної епохи\n",
    "        print(f\"Epoch {epoch+1} Results: \")\n",
    "        print(f\"Test Loss: {test_loss:.4f}\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # Збереження результатів\n",
    "        results.append({\n",
    "            \"Model\": model_type,\n",
    "            \"BatchSize\": batch_size,\n",
    "            \"LearningRate\": learning_rate,\n",
    "            \"Lag\": lag,\n",
    "            \"TestLoss\": test_loss,\n",
    "            \"MSE\": mse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2     \n",
    "    })\n",
    "\n",
    "# Збереження результатів у CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"experiment_results.csv\", index=False)\n",
    "print(\"Results saved to 'experiment_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d840d1a-a618-452d-a403-b1c2159548d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.7100,  91.5500,  74.6000,  96.5600, 100.9400, 117.8900, 110.1300,\n",
      "          82.2900, 117.6100, 111.8800,  60.4000],\n",
      "        [100.0700,  91.4300,  74.0400,  94.3400,  99.9600, 117.3300, 109.9700,\n",
      "          82.1300, 115.6300, 109.6000,  60.0300],\n",
      "        [100.3600,  91.4400,  74.2300,  94.8400, 100.5200, 117.8600, 109.9700,\n",
      "          82.3100, 116.2600, 110.2200,  60.3300],\n",
      "        [ 99.4200,  91.4400,  73.5600,  91.7100,  99.4000, 117.1500, 109.9800,\n",
      "          82.1300, 114.0300, 107.4900,  59.8600],\n",
      "        [100.1100,  91.4500,  74.0900,  93.6600, 100.0500, 117.6400, 109.9800,\n",
      "          82.2500, 115.4500, 109.1900,  60.1500],\n",
      "        [ 99.7900,  91.4700,  73.8600,  92.4600,  99.6800, 117.3300, 109.9800,\n",
      "          82.1500, 114.8000, 108.0700,  59.9800],\n",
      "        [ 99.7800,  91.4700,  73.8300,  92.5500,  99.6900, 117.2500, 109.9800,\n",
      "          82.0800, 114.7100, 108.3100,  59.9300],\n",
      "        [ 99.6300,  91.4600,  73.7400,  91.5500,  99.4500, 117.1900, 109.9800,\n",
      "          82.0700, 114.1900, 107.4200,  59.9000],\n",
      "        [ 99.0700,  91.4800,  73.3700,  92.0800,  98.8900, 116.5300, 109.9200,\n",
      "          81.7900, 113.9500, 107.6700,  59.5700],\n",
      "        [ 99.2000,  91.4800,  73.4600,  92.7100,  98.9400, 116.4200, 109.9200,\n",
      "          81.7200, 114.0700, 108.0400,  59.5300],\n",
      "        [ 98.9000,  91.5100,  73.2400,  92.7500,  98.6000, 116.1300, 109.9300,\n",
      "          81.6300, 113.6500, 107.9700,  59.3800],\n",
      "        [ 98.8300,  91.5100,  73.1600,  91.6400,  98.6800, 116.3100, 109.9500,\n",
      "          81.6700, 113.1800, 107.0700,  59.4500],\n",
      "        [ 98.6800,  91.5100,  73.1100,  92.0600,  98.4000, 116.0600, 109.9300,\n",
      "          81.5800, 113.1500, 107.3200,  59.2800],\n",
      "        [ 98.2400,  91.5000,  72.7500,  90.8200,  97.7900, 115.7300, 109.9500,\n",
      "          81.5400, 112.2400, 106.2500,  59.1100],\n",
      "        [ 98.5500,  91.5200,  72.9500,  92.9800,  98.1800, 115.7900, 109.9500,\n",
      "          81.4700, 113.4900, 108.0300,  59.1800]])\n",
      "tensor([0.0400])\n"
     ]
    }
   ],
   "source": [
    "X, Y = next(iter(test_loader))  # Замість test_dataloader\n",
    "print(X[0])\n",
    "print(Y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5df0dc-f2a2-4d37-ab85-253351f14963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (ipykernel)",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
